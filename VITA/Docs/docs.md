| ID do Artigo | Tecnologia | Como Foi Utilizada | Resultados |
| :--- | :--- | :--- | :--- |
| **Título:** A pilot study to identify autism related traits in spontaneous facial actions using computer vision<br>**Autores:** Manar D. Samada et al.<br>**Ano:** 2019<br>**DOI:** https://doi.org/10.1016/j.rasd.2019.05.001 | Visão Computacional, Captura de Movimento Facial sem Marcadores | Desenvolveram um estudo psicovisual humano para elicitar expressões faciais espontâneas em resposta a contextos sociais e emocionais. Utilizaram captura de movimento facial sem marcadores e métodos de visão computacional para rastrear ativações musculares faciais, codificando-as em dez unidades de ação facial (FAU). Realizaram testes estatísticos para identificar traços diferenciais entre indivíduos com Transtorno do Espectro Autista (TEA) e controles tipicamente em desenvolvimento (TDC). Foram recrutadas 20 crianças em idade escolar (10 com TEA, 10 TDC) e usados estímulos audiovisuais dinâmicos. | Revelaram diferenças significativas (p < 0.001) na ativação de dez FAUs e ativações contrastantes entre os grupos TEA e TDC. O grupo TEA mostrou prevalência incomum de "mouth frown" (FAU 15) e baixas correlações nas ativações temporais de vários pares de FAU (6-12, 10-12, 10-20), diferentemente do grupo TDC. As interpretações sugerem embotamento da expressão, falta de mimetismo e reação incongruente a emoções negativas no grupo TEA. A magnitude das ativações de FAU para o grupo TEA foi significativamente menor que para o grupo TDC. O framework proposto pode quantificar traços psicofísicos e ser replicado em estudos semelhantes. |
| **Título:** A Review on Computer Vision-Based Techniques for Autism Symptoms Detection and Recognition<br>**Autores:** Esraa T. Sadek et al.<br>**Ano:** Não especificado no excerto<br>**DOI:** Não disponível no excerto | Visão Computacional, Aprendizado de Máquina, Deep Learning | Este é um artigo de revisão que descreve protocolos de visão computacional e tecnologias de aprendizado de máquina para soluções de diagnóstico de autismo. Aborda a detecção de padrões de comportamentos motores repetitivos e discute a estimativa de pose do corpo humano e representação esquelética. Propõe um framework para detecção de sinais de autismo que inclui pré-processamento, extração de características do corpo humano usando estimadores de pose baseados em redes neurais (como OpenPose) e redes neurais para classificar padrões comportamentais. | Técnicas baseadas em visão computacional oferecem simplicidade e custos minimizados em comparação com outras técnicas de diagnóstico (EEG, fMRI). Comportamentos motores repetitivos podem ser rastreados e detectados. Ferramentas computacionais podem identificar características heterogêneas do TEA, melhorando a compreensão e o planejamento de intervenções. O DeepPose alcançou 69% de precisão e o modelo de J. Tompson et al. 82%. A visão computacional pode ajudar a identificar "sinais de alerta" precoces, levando a diagnósticos e tratamentos mais rápidos. |
| **Título:** Autism Spectrum Disorder Detection: Video Games based Facial Expression Diagnosis using Deep Learning<br>**Autores:** Morched Derbali et al.<br>**Ano:** Janeiro de 2023<br>**DOI:** 10.14569/IJACSA.2023.0140112 | Deep Learning (Rede Neural Convolucional - CNN), Aprendizado de Máquina | Propuseram um método de detecção de TEA usando expressões faciais baseadas em videogames. Utilizaram um dataset de 2.536 imagens faciais de crianças autistas e tipicamente em desenvolvimento. A expressão facial da criança é capturada por webcam enquanto ela joga um videogame, o vídeo é pré-processado e um modelo CNN (VGG) é treinado para prever se a criança é autista ou não a partir de frames do vídeo. A classificação final do vídeo é a média das classificações das imagens. | O modelo CNN e o deep learning geraram resultados de previsão com 92.3% de precisão. O modelo alcançou 92.3% de precisão no conjunto de testes e 87.3% no conjunto de validação com o modelo VGG. A precisão foi de 90.4%. O modelo pode extrair atributos faciais e detectar padrões de características faciais, como risos inapropriados, falta de sensibilidade à dor, incapacidade de manter contato visual adequado e reações inadequadas ao som. |
| **Título:** Automated identification of autism spectrum disorder from facial images using explainable deep learning models<br>**Autores:** El-Sayed Atlam et al.<br>**Ano:** 2025 (Recebido em 22 de abril de 2025; Aceito em 14 de julho de 2025)<br>**DOI:** Não disponível no excerto | Deep Learning (Redes Neurais Convolucionais - CNNs), IA Explicável (XAI) - LIME | Introduziram um framework de deep learning (ASD-FIC) para detecção automatizada de TEA usando análise de imagens faciais. Utilizaram CNNs pré-treinadas (VGG16, VGG19, InceptionV3, VGGFace, MobileNet) com técnicas avançadas de pré-processamento e aumento de dados (virar, girar, deslocar, zoom). Integraram métodos de XAI (LIME) para aumentar a interpretabilidade. O framework envolveu ajuste fino de hiperparâmetros e uso do dataset "Facial Image Data Set for Children with Autism" do Kaggle. | O modelo VGG19 alcançou uma precisão de 98.2%, superando muitos métodos de ponta. O framework melhorou tanto a precisão quanto a interpretabilidade. Após aumento de dados e configuração de hiperparâmetros, o VGG19 obteve 98.21% de acurácia, 99.28% de precisão, 97.16% de recall e 98.20% de F1-score. A interpretabilidade foi avaliada com LIME, que destacou regiões faciais específicas (olhos, boca) que mais contribuíram para as previsões do modelo. |
| **Título:** Computer Vision-based Interactive Autism Detection System using Deep Learning<br>**Autores:** Badhon Parvej et al.<br>**Ano:** Não especificado no excerto | Deep Learning (Rede Neural Convolucional - CNN), Visão Computacional | Empregaram classificadores de deep learning (VGG16 e VGG19) para diferenciar crianças autistas de crianças com desenvolvimento típico, com base em características faciais. Utilizaram um dataset de 2.940 imagens faciais de fontes públicas online. O pré-processamento incluiu limpeza, recorte e normalização das imagens. A função de ativação Softmax foi usada para a previsão da saída. Realizaram modificações em variáveis como número de épocas (100) e tamanho do lote (12). | A abordagem de deep learning alcançou a maior precisão de 88% com o VGG19, seguida por 86.3% com o VGG16. O VGG19 superou o VGG16 em precisão de teste. A arquitetura CNN proposta pode obter melhor desempenho de detecção com menos parâmetros, reduzindo o tempo de treinamento e tornando-o mais rápido e simples. A visão computacional serve como uma ferramenta automatizada para especialistas e famílias, possibilitando diagnósticos mais rápidos e precisos de autismo. |
| **Título:** Computer Vision Analysis for Quantification of Autism Risk Behaviors<br>**Autores:** Jordan Hashemi et al.<br>**Ano:** 2018 (Publicado em IEEE Transactions on Affective Computing)<br>**DOI:** Não disponível no excerto | Visão Computacional, Aprendizado de Máquina | Desenvolveram um aplicativo móvel com estímulos de vídeo para elicitar e quantificar respostas comportamentais específicas relacionadas ao TEA em crianças pequenas. Utilizaram a câmera frontal do dispositivo móvel para capturar e codificar automaticamente os comportamentos, focando em engajamento, respostas a chamadas pelo nome e emoção. Métodos de análise de vídeo e áudio foram usados para estudar a atenção e a expressão facial. A validação foi realizada com base em codificações manuais de especialistas, usando coeficientes de correlação intraclasse (ICC) e métricas como precisão, recall e F1-score. O estudo envolveu 33 crianças (18 não-TEA, 15 TEA) entre 16 e 31 meses. | Os resultados sugerem que métodos objetivos e automáticos podem auxiliar na análise comportamental e são adequados para estudos futuros em larga escala. Houve alta concordância entre os métodos automáticos propostos e os codificadores humanos especialistas. A confiabilidade interavaliador para detecção de engajamento foi excelente (ICC de 0.85 geral; 0.81 para TEA, 0.89 para não-TEA). Crianças com TEA apresentaram menor engajamento na tarefa em idades mais avançadas e menor porcentagem de emoções positivas em comparação com crianças sem risco (29.9% vs 35.1%). Os métodos permitem medições objetivas e granulares dos comportamentos, levando a definições refinadas de marcadores de risco. |
| **Título:** Deep learning for the identification of autism traits in children through facial expressions: a systematic review<br>**Autores:** Daniella Romani Palomino et al.<br>**Ano:** Junho de 2025<br>**DOI:** 10.11591/ijece.v15i3.pp3279-3290 | Deep Learning (Redes Neurais Convolucionais - CNNs) | Esta é uma revisão sistemática que examina a aplicação da inteligência artificial, especificamente deep learning, na detecção de traços de autismo através de expressões faciais. A busca foi estruturada utilizando a metodologia PICO (População, Intervenção, Comparação, Desfecho) em bases de dados como Scopus, PubMed e EBSCO. A revisão discute modelos de deep learning como VGG16, ResNet101 e MobileNet para análise de características faciais, rastreamento de olhar e extração de mapas de características. | Houve um crescimento notável na produção científica desde 2019, com ênfase em técnicas como CNNs e sistemas baseados em FACS-CNN. O deep learning melhorou a precisão diagnóstica, apesar dos desafios de qualidade e disponibilidade de dados. A capacidade do deep learning de analisar padrões de dados complexos é promissora para automatizar o processo de diagnóstico. A imagem facial oferece uma maneira rápida e acessível para a avaliação inicial. CNNs permitem o aprendizado de características relevantes de expressões faciais com maior precisão e generalização. |
| **Título:** Diagnosis of Autism in Children Using Deep Learning Techniques by Analyzing Facial Features<br>**Autores:** Pranavi Reddy and Andrew J<br>**Ano:** 2023 (Publicado em 22 de janeiro de 2024)<br>**DOI:** https://doi.org/10.3390/engproc2023059198 | Deep Learning (Redes Neurais Convolucionais - CNNs), Transfer Learning | O estudo propôs a detecção de autismo a partir de imagens faciais usando um modelo de deep learning. Utilizaram três modelos CNNs pré-treinados (VGG16, VGG19, EfficientNetB0) como extratores de características e classificadores binários. Os modelos foram treinados com um dataset público do Kaggle contendo 3014 imagens de crianças (autistas e não-autistas). O pré-processamento incluiu aumento e redimensionamento de imagens. Modelos pré-treinados foram modificados e aumentados com camadas adicionais para se adequarem ao dataset. Foi realizado ajuste de hiperparâmetros (20 épocas, taxa de aprendizado 0.001, tamanho do lote 64) e avaliação de otimizadores (Adagrad, Adam, Adamax), com Adamax mostrando o melhor resultado. | Os modelos alcançaram precisões de 84.66% (VGG16), 80.05% (VGG19) e 87.9% (EfficientNetB0). O VGG16 atingiu 84.67% de precisão e AUC de 90.73% com o otimizador Adagrad. O VGG19 teve um desempenho notável com 87.66% de precisão. O EfficientNetB0 superou o VGG16 e o VGG19 na avaliação. O otimizador Adamax produziu a maior precisão (88.33%) e AUC (95.44%) durante o ajuste de hiperparâmetros. O transfer learning permite adaptação eficaz a tarefas específicas de TEA, mesmo com dados limitados, melhorando a eficiência e precisão. |
| **Título:** Early Detection of Neurodevelopmental Disorders: Quantifying Autism Behavioral Markers with Computer Vision and Artificial Intelligence<br>**Autores:** Raksheet Jain, Divyansh Mangal<br>**Ano:** Não especificado no excerto | Visão Computacional, Inteligência Artificial (IA), Aprendizado de Máquina, Rede Neural Convolucional (CNN) com camadas ResNet, DeepFace | Apresentaram um método não invasivo e escalável para detecção precoce de autismo usando tecnologia de webcam padrão combinada com análise de IA. O sistema captura e analisa dados de rastreamento ocular, movimentos da cabeça e respostas comportamentais durante uma apresentação de vídeo controlada de 4 minutos. Um dataset proprietário de 147 crianças foi criado. Biomarcadores foram extraídos usando modelos de IA como DeepFace para análise facial. Os dados foram integrados com métricas de olhar e movimento da cabeça. Foram usados modelos de aprendizado de máquina (SVM, Árvores de Decisão, Random Forests, KNN, ANN, CNN com ResNet). A arquitetura da CNN incluía uma rede densa de 5 camadas com três camadas ocultas. | O modelo mais avançado, uma CNN com camadas ResNet, alcançou uma taxa de precisão de 91%. Essa alta precisão sugere uma identificação confiável do TEA em um estágio muito precoce. A IA agiliza o processo de diagnóstico, reduz a dependência de especialistas e torna a detecção mais objetiva e menos propensa a erros. A visão computacional em diagnósticos não invasivos pode revolucionar a saúde pediátrica. |
| **Título:** Leveraging artificial intelligence for diagnosis of children autism through facial expressions<br>**Autores:** Mahmood A. Mahmood et al.<br>**Ano:** 2025 (Recebido em 5 de fevereiro de 2025; Aceito em 25 de março de 2025)<br>**DOI:** Não disponível no excerto | Inteligência Artificial (IA), Deep Learning (DenseNet201, ResNet152, VGG16, VGG19, MobileNetV2, EfficientNet-B0), Transfer Learning, Fine-tuning, Vision Transformers (ViT) | Avaliaram modelos de deep learning usando transfer learning e fine-tuning para detectar dificuldades de aprendizagem relacionadas ao autismo em crianças. Avaliaram seis arquiteturas de deep learning (DenseNet201, ResNet152, VGG16, VGG19, MobileNetV2, EfficientNet-B0). Desenvolveram um modelo híbrido integrando ResNet152 com Vision Transformers (ViT). Utilizaram dados de imagens RGB de crianças com TEA diagnosticado do Kaggle. As imagens passaram por pré-processamento (normalização de pixel, redimensionamento, aumento de dados). O modelo híbrido combinou ResNet152 (últimas 20 camadas ajustadas, pré-treinadas no ImageNet) para características espaciais hierárquicas com ViT-Base-Patch16 para tokenização e atenção global. | O ResNet152 alcançou a maior precisão de 89% operando independentemente. O modelo híbrido ViT-ResNet152 alcançou uma precisão de 91.33%, melhorando o desempenho de classificação e a generalizabilidade para diferentes casos de TEA. O modelo híbrido superou os modelos individuais em todas as métricas: 91.33% de acurácia, 90.67% de precisão, 91.89% de recall, 91.28% de F1-score e 90.79% de especificidade. O modelo híbrido demonstrou velocidade de inferência em tempo real de 15 ms, permitindo sua implementação para aplicações clínicas. Ferramentas de IA são promissoras para métodos altamente precisos e padronizados de detecção precoce de TEA. |
| **Título:** Predictive approach for Autism Detection using Computer Vision and Deep Learning<br>**Autores:** Rajiv Pandey et al.<br>**Ano:** Não especificado no excerto | Inteligência Artificial (IA), Visão Computacional, Deep Learning (Redes Neurais Convolucionais - CNNs), Aprendizado de Máquina | Criaram e avaliaram um classificador binário de imagens usando deep learning baseado em visão computacional para previsão de autismo. O dataset foi compilado de Kaggle, Google Images e PubMed, com 1900 imagens de crianças com desenvolvimento típico e 1950 imagens de crianças com autismo. As imagens eram de crianças de 2 a 8 anos, excluindo menores de 2 anos devido ao desenvolvimento das características faciais. A arquitetura da CNN incluía uma rede densa de 5 camadas com três camadas ocultas para discernir padrões e classificar como "Autista" ou "Não-Autista". | O modelo alcançou 87.76% de precisão, 89.59% de recall e 88.87% de acurácia. Os métodos de visão computacional, baseados unicamente em dados faciais, são eficazes na detecção de TEA em estágios iniciais. Essa abordagem sugere um método mais simples e poderoso para intervenções oportunas. Métodos de IA oferecem avaliações objetivas e quantitativas do TEA, minimizando a subjetividade e a variabilidade. |
| **Título:** Computer vision in autism spectrum disorder research: a systematic review of published studies from 2009 to 2019<br>**Autores:** Ryan Anthony J. de Belen et al.<br>**Ano:** 2020<br>**DOI:** https://doi.org/10.1038/s41398-020-01015-w | Visão Computacional, Deep Learning, Aprendizado de Máquina | Esta é uma revisão sistemática que examina como a análise por visão computacional tem sido útil no diagnóstico, terapia e pesquisa geral do TEA. A revisão abrangeu publicações indexadas no PubMed, IEEE Xplore e ACM Digital Library de 2009 a 2019, usando termos de busca específicos. Os artigos elegíveis foram categorizados com base em marcadores comportamentais/biológicos quantificados (RM/fMRI, expressão facial/emoção, dados de olhar, controle motor/padrão de movimento, comportamentos estereotipados, dados multimodais). Também foram revisados datasets públicos aplicáveis à pesquisa em visão computacional para autismo. | A análise por visão computacional é útil para quantificar marcadores comportamentais/biológicos, levando a uma análise mais objetiva na pesquisa do autismo. A visão computacional fornece informações objetivas não intrusivas sobre a condição do paciente. Pode detectar automaticamente sintomas para pré-diagnosticar mais de 30 condições. As abordagens baseadas em deep learning mostraram desempenho superior em tarefas de extração de características e classificação em comparação com as abordagens tradicionais de visão computacional. Métodos multimodais alcançam desempenho superior combinando conhecimento de diferentes modalidades. |
| **Título:** Using computer vision to quantify facial expressions of children with autism during naturalistic social interactions<br>**Autores:** Liora Manelis-Baram et al.<br>**Ano:** Não especificado no excerto | Visão Computacional, Algoritmos de Análise Facial | Analisaram mais de 5 milhões de frames de vídeo de 100 crianças verbais (2-7 anos), incluindo 72 com autismo e 28 controles. Utilizaram múltiplos algoritmos de visão computacional (iMotions FACET, iMotions AFFDEX, OpenFace, FaceReader, Py-Feat) para identificar expressões faciais em gravações de vídeo. As gravações eram avaliações clínicas do Banco de Dados Nacional de Autismo de Israel (NADI). O objetivo era quantificar o uso atípico de expressões faciais durante interações sociais naturalísticas. Correlações de Pearson e ANCOVA foram usadas para análise. | As correlações de Pearson entre FaceReader e iMotions foram relativamente altas (TEA: r=0.75; controle: r=0.64), mas as correlações com Py-Feat foram mais baixas. A maioria dos tamanhos de efeito estava na faixa baixa a média, sugerindo uma concordância relativamente fraca entre os algoritmos. Para iMotions, não houve diferença significativa entre os grupos TEA e controle para felicidade, raiva, nojo ou medo. O estudo destaca a necessidade de novos algoritmos de análise de expressões faciais treinados especificamente para identificar expressões de crianças pequenas em interações naturalísticas. |
